{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d697da3-7e3d-4c0b-bff5-95763a05644e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.12 | packaged by conda-forge | (main, Oct 22 2025, 23:25:55) [GCC 14.3.0]\n",
      "Bucket: sagemaker-us-east-1-341104199580\n",
      "s3fs installed ✅\n",
      "2026-02-02 00:56:24       1785 model_profiles.csv\n",
      "2026-02-02 01:03:35    1322198 synthetic_requests_labeled.csv\n",
      "2026-02-02 01:05:44    2690432 synthetic_requests_labeled_v2.csv\n",
      "2026-02-02 00:53:53       7312 aimodelpoll.csv\n",
      "2026-02-02 00:53:53      19349 lifearchitectmodels.csv\n"
     ]
    }
   ],
   "source": [
    "import sys, sagemaker, pandas as pd\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Bucket:\", bucket)\n",
    "\n",
    "# Check if s3fs exists\n",
    "try:\n",
    "    import s3fs\n",
    "    print(\"s3fs installed ✅\")\n",
    "except Exception as e:\n",
    "    print(\"s3fs missing ❌\", e)\n",
    "\n",
    "# Confirm the file exists in S3\n",
    "!aws s3 ls s3://{bucket}/processed/\n",
    "!aws s3 ls s3://{bucket}/raw/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaacec84-d973-4837-963e-a7e34861b675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profiles shape: (17, 9)\n",
      "['Model', 'quality_score_mean', 'quality_score_max', 'achievements_count', 'domains_count', 'peer_reviewed_rate', 'outperforms_rate', 'domains_covered', 'quality_tier']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>quality_score_mean</th>\n",
       "      <th>quality_score_max</th>\n",
       "      <th>achievements_count</th>\n",
       "      <th>domains_count</th>\n",
       "      <th>peer_reviewed_rate</th>\n",
       "      <th>outperforms_rate</th>\n",
       "      <th>domains_covered</th>\n",
       "      <th>quality_tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claude 3.6S</td>\n",
       "      <td>5.415792</td>\n",
       "      <td>5.415792</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Persuasion</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o3-mini-high</td>\n",
       "      <td>5.360643</td>\n",
       "      <td>5.360643</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Health reviews</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o1</td>\n",
       "      <td>5.040036</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Maths, Medicine</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT-4, etc</td>\n",
       "      <td>4.694612</td>\n",
       "      <td>4.694612</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Emotional intelligence</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o4-mini</td>\n",
       "      <td>4.614010</td>\n",
       "      <td>4.614010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Finance</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gemini 3</td>\n",
       "      <td>4.476880</td>\n",
       "      <td>4.476880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Transcription</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPT-4.5</td>\n",
       "      <td>4.355234</td>\n",
       "      <td>4.355234</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Being human</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bing Chat</td>\n",
       "      <td>3.885513</td>\n",
       "      <td>4.067345</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Japan: National Medical Licensure Examination,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>davinci</td>\n",
       "      <td>3.718992</td>\n",
       "      <td>4.024340</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>General knowledge, IQ (Binet-Simon Scale, verb...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>3.131280</td>\n",
       "      <td>5.168894</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>Academia, Aerospace, Art (via prompting Midjou...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  quality_score_mean  quality_score_max  achievements_count  \\\n",
       "0   Claude 3.6S            5.415792           5.415792                   1   \n",
       "1  o3-mini-high            5.360643           5.360643                   1   \n",
       "2            o1            5.040036           5.500000                   2   \n",
       "3    GPT-4, etc            4.694612           4.694612                   1   \n",
       "4       o4-mini            4.614010           4.614010                   1   \n",
       "5      Gemini 3            4.476880           4.476880                   1   \n",
       "6       GPT-4.5            4.355234           4.355234                   1   \n",
       "7     Bing Chat            3.885513           4.067345                   2   \n",
       "8       davinci            3.718992           4.024340                   4   \n",
       "9         GPT-4            3.131280           5.168894                  16   \n",
       "\n",
       "   domains_count  peer_reviewed_rate  outperforms_rate  \\\n",
       "0              1                1.00            1.0000   \n",
       "1              1                1.00            1.0000   \n",
       "2              2                1.00            1.0000   \n",
       "3              1                1.00            1.0000   \n",
       "4              1                1.00            1.0000   \n",
       "5              1                0.00            1.0000   \n",
       "6              1                1.00            1.0000   \n",
       "7              2                0.50            1.0000   \n",
       "8              3                0.25            1.0000   \n",
       "9             15                0.75            0.9375   \n",
       "\n",
       "                                     domains_covered  quality_tier  \n",
       "0                                         Persuasion             5  \n",
       "1                                     Health reviews             5  \n",
       "2                                    Maths, Medicine             5  \n",
       "3                             Emotional intelligence             5  \n",
       "4                                            Finance             4  \n",
       "5                                      Transcription             4  \n",
       "6                                        Being human             4  \n",
       "7  Japan: National Medical Licensure Examination,...             3  \n",
       "8  General knowledge, IQ (Binet-Simon Scale, verb...             3  \n",
       "9  Academia, Aerospace, Art (via prompting Midjou...             3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd, sagemaker\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "profiles = pd.read_csv(f\"s3://{bucket}/processed/model_profiles.csv\")\n",
    "print(\"profiles shape:\", profiles.shape)\n",
    "print(profiles.columns.tolist())\n",
    "display(profiles.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1558764b-a9fc-447f-9c6a-8c87b4f70648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using models: ['Claude 3.6S', 'o3-mini-high', 'o1', 'GPT-4, etc', 'o4-mini', 'Gemini 3']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# -------------------------\n",
    "# Load model profiles\n",
    "# -------------------------\n",
    "profiles = pd.read_csv(f\"s3://{bucket}/processed/model_profiles.csv\")\n",
    "profiles[\"Model\"] = profiles[\"Model\"].astype(str).str.strip()\n",
    "profiles = profiles[profiles[\"Model\"].notna() & (profiles[\"Model\"] != \"nan\")].copy()\n",
    "\n",
    "# Using top 6 models\n",
    "profiles = profiles.sort_values([\"quality_tier\",\"quality_score_mean\"], ascending=[False, False]).head(6).copy()\n",
    "models = profiles[\"Model\"].tolist()\n",
    "print(\"Using models:\", models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0167d34e-6492-405a-ad86-81d70ef1aca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fallback model: Claude 3.6S\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Improved synthetic traits (wider spread)\n",
    "# -------------------------\n",
    "# cost rises with quality tier (more realistic)\n",
    "profiles[\"cost_per_token\"] = 0.0000006 * (1.8 ** (profiles[\"quality_tier\"] - 1))   # bigger gap\n",
    "\n",
    "# latency increases with quality tier but not crazy\n",
    "profiles[\"base_latency_ms\"] = 60 + 55 * (profiles[\"quality_tier\"] - 1)            # 60..335\n",
    "profiles[\"per_token_ms\"] = 0.010 + 0.008 * (profiles[\"quality_tier\"] - 1)         # 0.01..0.042\n",
    "\n",
    "# quality score normalized\n",
    "q = profiles[\"quality_score_mean\"].astype(float)\n",
    "profiles[\"quality_score_norm\"] = ((q - q.min()) / (q.max() - q.min() + 1e-9)).clip(0, 1)\n",
    "\n",
    "mp = profiles.set_index(\"Model\")[[\"base_latency_ms\",\"per_token_ms\",\"cost_per_token\",\"quality_score_norm\",\"quality_tier\"]].to_dict(\"index\")\n",
    "fallback_model = profiles.sort_values(\"quality_score_norm\", ascending=False).iloc[0][\"Model\"]\n",
    "print(\"Fallback model:\", fallback_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "493abdd7-4e5e-44fd-b038-b2cb9e0b3a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requests: (40000, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>tokens_total</th>\n",
       "      <th>domain</th>\n",
       "      <th>latency_requirement_ms</th>\n",
       "      <th>quality_req_tier</th>\n",
       "      <th>quality_requirement</th>\n",
       "      <th>log_tokens_total</th>\n",
       "      <th>strict_latency</th>\n",
       "      <th>domain_penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2103</td>\n",
       "      <td>1217</td>\n",
       "      <td>3320</td>\n",
       "      <td>writing</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.725</td>\n",
       "      <td>8.108021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2353</td>\n",
       "      <td>1094</td>\n",
       "      <td>3447</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600</td>\n",
       "      <td>8.145550</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>511</td>\n",
       "      <td>475</td>\n",
       "      <td>986</td>\n",
       "      <td>chat</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350</td>\n",
       "      <td>6.894670</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>191</td>\n",
       "      <td>395</td>\n",
       "      <td>code</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0.725</td>\n",
       "      <td>5.981414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>141</td>\n",
       "      <td>262</td>\n",
       "      <td>writing</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600</td>\n",
       "      <td>5.572154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_tokens  output_tokens  tokens_total     domain  \\\n",
       "0           2103           1217          3320    writing   \n",
       "1           2353           1094          3447  reasoning   \n",
       "2            511            475           986       chat   \n",
       "3            204            191           395       code   \n",
       "4            121            141           262    writing   \n",
       "\n",
       "   latency_requirement_ms  quality_req_tier  quality_requirement  \\\n",
       "0                     200                 4                0.725   \n",
       "1                    3000                 3                0.600   \n",
       "2                     400                 1                0.350   \n",
       "3                     800                 4                0.725   \n",
       "4                     400                 3                0.600   \n",
       "\n",
       "   log_tokens_total  strict_latency  domain_penalty  \n",
       "0          8.108021               1            0.04  \n",
       "1          8.145550               0            0.08  \n",
       "2          6.894670               1            0.00  \n",
       "3          5.981414               0            0.07  \n",
       "4          5.572154               1            0.04  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Generate synthetic requests (rebalanced)\n",
    "# -------------------------\n",
    "rng = np.random.default_rng(7)\n",
    "N = 40000\n",
    "\n",
    "mix = rng.choice([0,1,2], size=N, p=[0.50,0.40,0.10])\n",
    "prompt_tokens = np.where(\n",
    "    mix==0, rng.integers(20, 500, size=N),\n",
    "    np.where(mix==1, rng.integers(500, 2500, size=N), rng.integers(2500, 10000, size=N))\n",
    ")\n",
    "output_tokens = (prompt_tokens * rng.uniform(0.15,0.7,size=N) + rng.integers(20,250,size=N)).astype(int)\n",
    "output_tokens = np.clip(output_tokens, 30, 3000)\n",
    "\n",
    "domains = rng.choice([\"chat\",\"writing\",\"code\",\"qa\",\"reasoning\"], size=N, p=[0.28,0.20,0.18,0.20,0.14])\n",
    "lat_req = rng.choice([200,400,800,1500,3000,6000], size=N, p=[0.10,0.15,0.25,0.25,0.18,0.07])\n",
    "\n",
    "# KEY CHANGE: quality requirement is softened (more feasible competition)\n",
    "# Instead of mapping tier -> 0..1, map tier -> 0.35..0.85\n",
    "q_tier = rng.choice([1,2,3,4,5], size=N, p=[0.25,0.28,0.25,0.15,0.07])\n",
    "q_req = 0.35 + (q_tier - 1) * (0.50/4.0)   # 0.35..0.85\n",
    "\n",
    "requests = pd.DataFrame({\n",
    "    \"prompt_tokens\": prompt_tokens,\n",
    "    \"output_tokens\": output_tokens,\n",
    "    \"tokens_total\": prompt_tokens + output_tokens,\n",
    "    \"domain\": domains,\n",
    "    \"latency_requirement_ms\": lat_req,\n",
    "    \"quality_req_tier\": q_tier,\n",
    "    \"quality_requirement\": q_req,\n",
    "})\n",
    "requests[\"log_tokens_total\"] = np.log1p(requests[\"tokens_total\"])\n",
    "requests[\"strict_latency\"] = (requests[\"latency_requirement_ms\"] <= 400).astype(int)\n",
    "\n",
    "# Domain penalty still matters but slightly lower so mid models can compete\n",
    "domain_penalty = {\"chat\":0.00,\"writing\":0.04,\"qa\":0.03,\"code\":0.07,\"reasoning\":0.08}\n",
    "requests[\"domain_penalty\"] = requests[\"domain\"].map(domain_penalty).fillna(0.05)\n",
    "\n",
    "print(\"Requests:\", requests.shape)\n",
    "display(requests.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8605988d-e063-4a61-800b-ea5d85a503e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution (should be multi-class):\n",
      "label_model\n",
      "Claude 3.6S    1.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Label policy: cheapest feasible model\n",
    "# -------------------------\n",
    "labels = []\n",
    "for _, r in requests.iterrows():\n",
    "    tokens = r[\"tokens_total\"]\n",
    "    long_pen = 0.08 if tokens > 4000 else 0.0\n",
    "\n",
    "    feas = []\n",
    "    for m in models:\n",
    "        base = mp[m][\"base_latency_ms\"]\n",
    "        per  = mp[m][\"per_token_ms\"]\n",
    "        cpt  = mp[m][\"cost_per_token\"]\n",
    "        qn   = mp[m][\"quality_score_norm\"]\n",
    "\n",
    "        pred_lat = (base + per * tokens) * 1.25  # slightly less pessimistic than 1.35\n",
    "        pred_q   = np.clip(qn - r[\"domain_penalty\"] - long_pen, 0, 1)\n",
    "        pred_c   = cpt * tokens\n",
    "\n",
    "        if (pred_lat <= r[\"latency_requirement_ms\"]) and (pred_q >= r[\"quality_requirement\"]):\n",
    "            feas.append((pred_c, m))\n",
    "\n",
    "    labels.append(sorted(feas)[0][1] if feas else fallback_model)\n",
    "\n",
    "requests[\"label_model\"] = labels\n",
    "print(\"\\nLabel distribution (should be multi-class):\")\n",
    "print(requests[\"label_model\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1921a5a9-cc94-4b2d-852e-b4e6f116b16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Router report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Claude 3.6S       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       1.00      1.00      1.00      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Train router (RandomForest)\n",
    "# -------------------------\n",
    "X = requests[[\n",
    "    \"prompt_tokens\",\"output_tokens\",\"tokens_total\",\"log_tokens_total\",\n",
    "    \"latency_requirement_ms\",\"quality_requirement\",\"quality_req_tier\",\"strict_latency\"\n",
    "]].copy()\n",
    "X = pd.get_dummies(pd.concat([X, requests[[\"domain\"]]], axis=1), columns=[\"domain\"], drop_first=False)\n",
    "\n",
    "y = requests[\"label_model\"].astype(\"category\")\n",
    "y_codes = y.cat.codes\n",
    "label_names = list(y.cat.categories)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_codes, test_size=0.2, random_state=42, stratify=y_codes\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=600, min_samples_leaf=2, n_jobs=-1, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)\n",
    "proba = rf.predict_proba(X_test)\n",
    "\n",
    "print(\"\\nRouter report:\")\n",
    "print(classification_report(y_test, pred, target_names=label_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfb46394-a69b-47ae-b069-bb0587674bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Enhancement: feasibility-gated inference + confidence fallback\n",
    "# -------------------------\n",
    "# Gate: if predicted model is infeasible, choose cheapest feasible.\n",
    "# If nothing feasible, choose fallback.\n",
    "# Also: if confidence < threshold, choose cheapest feasible.\n",
    "conf_thresh = 0.55\n",
    "\n",
    "# Rebuild request slice for test set\n",
    "idx = np.arange(len(X))\n",
    "_, idx_test = train_test_split(idx, test_size=0.2, random_state=42, stratify=y_codes)\n",
    "req_test = requests.iloc[idx_test].reset_index(drop=True)\n",
    "\n",
    "pred_codes = pred\n",
    "pred_models = np.array([label_names[c] for c in pred_codes])\n",
    "conf = proba.max(axis=1)\n",
    "\n",
    "def cheapest_feasible(row):\n",
    "    tokens = row[\"tokens_total\"]\n",
    "    long_pen = 0.08 if tokens > 4000 else 0.0\n",
    "    feas = []\n",
    "    for m in models:\n",
    "        base = mp[m][\"base_latency_ms\"]\n",
    "        per  = mp[m][\"per_token_ms\"]\n",
    "        cpt  = mp[m][\"cost_per_token\"]\n",
    "        qn   = mp[m][\"quality_score_norm\"]\n",
    "        pred_lat = (base + per * tokens) * 1.25\n",
    "        pred_q = np.clip(qn - row[\"domain_penalty\"] - long_pen, 0, 1)\n",
    "        pred_c = cpt * tokens\n",
    "        if (pred_lat <= row[\"latency_requirement_ms\"]) and (pred_q >= row[\"quality_requirement\"]):\n",
    "            feas.append((pred_c, m))\n",
    "    return sorted(feas)[0][1] if feas else fallback_model\n",
    "\n",
    "# Apply gating\n",
    "gated_models = []\n",
    "for i in range(len(req_test)):\n",
    "    if conf[i] < conf_thresh:\n",
    "        gated_models.append(cheapest_feasible(req_test.loc[i]))\n",
    "    else:\n",
    "        # check feasibility for predicted model; if infeasible => cheapest feasible\n",
    "        m = pred_models[i]\n",
    "        row = req_test.loc[i]\n",
    "        tokens = row[\"tokens_total\"]\n",
    "        long_pen = 0.08 if tokens > 4000 else 0.0\n",
    "        base = mp[m][\"base_latency_ms\"]\n",
    "        per  = mp[m][\"per_token_ms\"]\n",
    "        qn   = mp[m][\"quality_score_norm\"]\n",
    "        pred_lat = (base + per * tokens) * 1.25\n",
    "        pred_q = np.clip(qn - row[\"domain_penalty\"] - long_pen, 0, 1)\n",
    "        if (pred_lat <= row[\"latency_requirement_ms\"]) and (pred_q >= row[\"quality_requirement\"]):\n",
    "            gated_models.append(m)\n",
    "        else:\n",
    "            gated_models.append(cheapest_feasible(row))\n",
    "\n",
    "gated_models = np.array(gated_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2db4defe-66f4-40b3-8580-372628eaabe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy</th>\n",
       "      <th>avg_cost</th>\n",
       "      <th>sla_rate</th>\n",
       "      <th>p95_latency_ms</th>\n",
       "      <th>avg_quality</th>\n",
       "      <th>fallback_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>router_raw</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.814375</td>\n",
       "      <td>830.241125</td>\n",
       "      <td>0.953622</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>router_gated_conf</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.814375</td>\n",
       "      <td>830.241125</td>\n",
       "      <td>0.953622</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>always_cheapest</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>670.016625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>always_best_quality</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.814375</td>\n",
       "      <td>830.241125</td>\n",
       "      <td>0.953622</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                policy  avg_cost  sla_rate  p95_latency_ms  avg_quality  \\\n",
       "0           router_raw  0.012987  0.814375      830.241125     0.953622   \n",
       "1    router_gated_conf  0.012987  0.814375      830.241125     0.953622   \n",
       "2      always_cheapest  0.007215  0.000000      670.016625     0.000000   \n",
       "3  always_best_quality  0.012987  0.814375      830.241125     0.953622   \n",
       "\n",
       "   fallback_rate  \n",
       "0            1.0  \n",
       "1            1.0  \n",
       "2            0.0  \n",
       "3            1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./synthetic_requests_labeled_v2.csv to s3://sagemaker-us-east-1-341104199580/processed/synthetic_requests_labeled_v2.csv\n",
      "upload: ./rf_router_v2.joblib to s3://sagemaker-us-east-1-341104199580/models/rf_router_v2.joblib\n",
      "Saved v2 dataset + model\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Evaluate cost + SLA for ungated vs gated vs baselines\n",
    "# -------------------------\n",
    "def eval_policy(chosen_models, df_req):\n",
    "    base = np.array([mp[m][\"base_latency_ms\"] for m in chosen_models])\n",
    "    per  = np.array([mp[m][\"per_token_ms\"] for m in chosen_models])\n",
    "    cpt  = np.array([mp[m][\"cost_per_token\"] for m in chosen_models])\n",
    "    qn   = np.array([mp[m][\"quality_score_norm\"] for m in chosen_models])\n",
    "\n",
    "    tokens = df_req[\"tokens_total\"].values\n",
    "    lat_req = df_req[\"latency_requirement_ms\"].values\n",
    "    q_req = df_req[\"quality_requirement\"].values\n",
    "    dom_pen = df_req[\"domain_penalty\"].values\n",
    "    long_pen = (tokens > 4000).astype(float) * 0.08\n",
    "\n",
    "    pred_lat = (base + per * tokens) * 1.25\n",
    "    pred_q = np.clip(qn - dom_pen - long_pen, 0, 1)\n",
    "    pred_cost = cpt * tokens\n",
    "    feasible = (pred_lat <= lat_req) & (pred_q >= q_req)\n",
    "\n",
    "    return {\n",
    "        \"avg_cost\": float(pred_cost.mean()),\n",
    "        \"sla_rate\": float(feasible.mean()),\n",
    "        \"p95_latency_ms\": float(np.percentile(pred_lat, 95)),\n",
    "        \"avg_quality\": float(pred_q.mean()),\n",
    "        \"fallback_rate\": float((chosen_models == fallback_model).mean())\n",
    "    }\n",
    "\n",
    "cheapest_model = profiles.sort_values(\"cost_per_token\").iloc[0][\"Model\"]\n",
    "bestq_model = profiles.sort_values(\"quality_score_norm\", ascending=False).iloc[0][\"Model\"]\n",
    "\n",
    "res_ungated = eval_policy(pred_models[:len(req_test)], req_test)\n",
    "res_gated   = eval_policy(gated_models, req_test)\n",
    "res_cheapest= eval_policy(np.array([cheapest_model]*len(req_test)), req_test)\n",
    "res_bestq   = eval_policy(np.array([bestq_model]*len(req_test)), req_test)\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"policy\":\"router_raw\", **res_ungated},\n",
    "    {\"policy\":\"router_gated_conf\", **res_gated},\n",
    "    {\"policy\":\"always_cheapest\", **res_cheapest},\n",
    "    {\"policy\":\"always_best_quality\", **res_bestq},\n",
    "])\n",
    "display(summary)\n",
    "\n",
    "# -------------------------\n",
    "# Save artifacts\n",
    "# -------------------------\n",
    "requests.to_csv(\"synthetic_requests_labeled_v2.csv\", index=False)\n",
    "joblib.dump(rf, \"rf_router_v2.joblib\")\n",
    "\n",
    "!aws s3 cp synthetic_requests_labeled_v2.csv s3://{bucket}/processed/synthetic_requests_labeled_v2.csv\n",
    "!aws s3 cp rf_router_v2.joblib s3://{bucket}/models/rf_router_v2.joblib\n",
    "\n",
    "print(\"Saved v2 dataset + model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b65e8-053a-469e-83d9-d240dd3c93c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
